{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gzip\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import random \n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will explore opinion mining and sentiment analysis through the use of natural language processing. Our dataset consists of reviews of electronic products scraped form Amazon and available here: http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "The objective of this analysis is to use the reviews of a product to extract meaningful concepts about it. Such concepts can then be used to help the user make faster and more informed decisions when shopping. The extracted concepts consist of pairs of words that describe a property of the product. Those pairs are either of the type adjective-noun or adverb-past participle.\n",
    "\n",
    "For example:\n",
    "\n",
    "* Adjective - Nouns: (good, quality) (low, price) (best, deal)\n",
    "* Adverb - Past Participle pairs such as (well, made) (poorly, assembled)\n",
    "\n",
    "The concepts can then be categorised into positive and negative opinions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<ol>\n",
    "<li> <a href=\"#Data-Overview\">Data Overview</a>\n",
    "    <ol>\n",
    "        <li><a href=\"#Reading-the-data\">Reading the data</a></li>\n",
    "        <li><a href=\"#Data-Overview\">Formats</a></li>\n",
    "        <li><a href=\"#Missing-values\">Missing values</a></li>\n",
    "        <li><a href=\"#Distributions\">Distributions</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "<p></p>\n",
    "<li> <a href=\"#Characteristic-Exctraction\">Characteristic exctraction</a>\n",
    "<ol>\n",
    "        <li><a href=\"#Data-Overview\">Data Overview</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "<p></p>\n",
    "<li><a href=\"#Sentiment-Analysis\">Sentiment Analysis</a>\n",
    "<ol>\n",
    "        <li><a href=\"#SentiWordNet\">SentiWordNet</a></li>\n",
    "        <li><a href=\"#Machine-Learning\">Machine Learning</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "<p></p>\n",
    "<li><a href=\"#Applications\">Applications</a>\n",
    "<ol>\n",
    "        <li><a href=\"#Brand-Rating\">Brand Rating</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data \n",
    "**<a href=\"#Table-of-Contents\">Table of contents</a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def readSerialized(path):\n",
    "    return pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_elec = readSerialized('serialized_electronics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta = readSerialized('metadata_electronics_serialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now discribe the different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elec['reviewTime']  = pd.to_datetime(df_elec['reviewTime'],format='%m %d, %Y')\n",
    "df_elec.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* summary: The summary of the product\n",
    "* reviewerName: The reviewer name\n",
    "* reviewTime: The review time in the datetime type\n",
    "* overall: The rating of the product from 1 to 5 included\n",
    "* asin: The id of the product\n",
    "* helpfull: The helpfulness of the comment. It is stored as an array; the first element is the number of positive votes the second element is the total number of votes for the comment.\n",
    "* unixReviewTime: The review time in the unix format\n",
    "* reviewerID: The reviewer id\n",
    "* reviewText: The text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = df_meta[pd.notnull(df_meta['brand'])]\n",
    "df_meta.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* title: The name of the product\n",
    "* description: The description of the product\n",
    "* imUrl: The url of the image\n",
    "* categories: The categories of the product, stored as an array\n",
    "* asin: The id of the product\n",
    "* price: The price of the product\n",
    "* selesRank: The sales rank, stored as dictionary mapping the category to the rank\n",
    "* related: The related products, stored as dictionary mapping a tag (also_bought, bought_together,...) to the asin\n",
    "* brand: The name of the brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the data, we discarded every null entries in price and reviewLength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged = df_meta.merge(df_elec, left_on='asin', right_on='asin', how='inner')\n",
    "df_merged['reviewLength'] = df_merged['reviewText'].str.len()\n",
    "\n",
    "df_plot = df_merged.copy()\n",
    "df_plot = df_plot[pd.notnull(df_plot['price'])]\n",
    "df_plot = df_plot[pd.notnull(df_plot['reviewLength'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the scatter matrix of the price, the review length and the overall score, to have some insight on the global distribution of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df_plot[['price','reviewLength','overall']], alpha=0.05, figsize=(15, 15), diagonal='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plotted the price over the review length to see in more details the data. We can directly see that there is a lot of noise (as expected). We also see that most of the mass is concentrated in a rather small interval; indeed the median of the price is 28.5 and the median of the text length is 312."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(y='reviewLength', x='price', data=df_plot,scatter_kws={'s':5},line_kws={'color':'r'},order=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plotted the distributions of the reviewLength over the overall. We can see that the extremes are less present in the data. Indeed, the review length is smaller for good reviews, this can be explained by the fact those reviews are synthetic: “Well made”, “Good Product”. The reviews that have a bad score (2) tend to be larger, as the critic can be big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='overall', x='reviewLength', data=df_plot, orient='h', showfliers=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we interested ourselves to the distribution of the price and the review length by plotting their density and the box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "sns.boxplot(data= df_plot[['price']],orient='h', showfliers=False,ax=axes[0,0])\n",
    "df_plot[['price']].plot.kde(ax=axes[0,1])\n",
    "sns.boxplot(data= df_plot[['reviewLength']],orient='h', showfliers=False,ax=axes[1,0])\n",
    "df_plot[['reviewLength']].plot.kde(ax=axes[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to fit a specific distribution; the exponential distribution to the data provided. We see that if we pick lambda = 65, we get a close approximation to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "d = df_plot[['price']]\n",
    "ax = d.plot.kde()\n",
    "x = ax.get_children()[0]._x\n",
    "y = ax.get_children()[0]._y\n",
    "\n",
    "scale = 66\n",
    "loc = -480\n",
    "\n",
    "pdf_fitted = scipy.stats.expon.pdf(x - loc, scale=scale)\n",
    "plt.plot(pdf_fitted,label= ('exp lambda = ' + str(scale)))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to fit a specific distribution; the pareto distribution to the data provided. We see that if we pick b = 1, we get a close approximation to the result up to a multiplicative constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pareto\n",
    "import scipy.stats\n",
    "\n",
    "d = df_plot[['reviewLength']]\n",
    "ax = d.plot.kde()\n",
    "\n",
    "b = 1\n",
    "x = np.linspace(pareto.ppf(0.01, b),pareto.ppf(0.99, b), 50000)\n",
    "pdf_fitted = scipy.stats.pareto.pdf(x,b = b)/500\n",
    "plt.plot(pdf_fitted,label= 'exp')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the correlation between the price, reviewLength, and the overall. We can see that the overall doesn't seem to be a lot correlated between the price and the review length. But more interestingly there seem to be some correlation between the price and the review lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[['price','reviewLength','overall']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characteristic Exctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterTags(w1,w2):\n",
    "    return (nltk.pos_tag(nltk.word_tokenize(w1))[0][1] == 'JJ' and nltk.pos_tag(nltk.word_tokenize(w2))[0][1] == 'NN') or \\\n",
    "     (nltk.pos_tag(nltk.word_tokenize(w1))[0][1] == 'RB' and nltk.pos_tag(nltk.word_tokenize(w2))[0][1] == 'VBN')\n",
    "\n",
    "def getBest(text):\n",
    "    ignored_words = nltk.corpus.stopwords.words('english')\n",
    "    word_filter = lambda w: len(w) < 3 or w.lower() in ignored_words\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    \n",
    "    finder = nltk.BigramCollocationFinder.from_words(tokens)\n",
    "    finder.apply_word_filter(word_filter)    \n",
    "    finder.apply_freq_filter(1)\n",
    "    res = finder.ngram_fd.most_common(1)\n",
    "        \n",
    "    res = [x for x in res if filterTags(x[0][0],x[0][1])]\n",
    "\n",
    "    if(len(res) > 0):\n",
    "        return res\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "df_product = df_elec.groupby([\"asin\"])['reviewText'].agg(lambda x:''.join(set(x))).reset_index()\n",
    "df_product = df_product.sample(n=10000)\n",
    "\n",
    "start = timer()\n",
    "df_product[\"reviewText\"] = df_product[\"reviewText\"].apply(lambda x: getBest(x))\n",
    "end = timer()\n",
    "print(end - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = df_product.dropna(how = 'any')\n",
    "df_product.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "np.random.seed(42)\n",
    "\n",
    "df_ML = df_elec[(df_elec[\"reviewText\"].str.len()<100)].copy()\n",
    "df_ML['score'] = df_elec[\"overall\"].apply(lambda x : -1 if x < 3 else 1)\n",
    "df_ML[\"reviewText\"] = df_ML[\"reviewText\"].apply(lambda x: x.lower())\n",
    "\n",
    "df_0 = (df_ML[df_ML[\"score\"] == -1])\n",
    "df_1 = (df_ML[df_ML[\"score\"] == 1])\n",
    "\n",
    "if df_0.shape[0] > df_1.shape[0]:\n",
    "    df_0 = df_0.sample(df_1.shape[0])\n",
    "else:\n",
    "    df_1 = df_1.sample(df_0.shape[0])\n",
    "    \n",
    "sentiment_data = pd.concat([df_0, df_1])\n",
    "X = sentiment_data[\"reviewText\"]\n",
    "y = sentiment_data[\"score\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_clf = Pipeline([\n",
    "('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "ngram_range=(1, 2),\n",
    "tokenizer=word_tokenize, \n",
    "# tokenizer=lambda text: mark_negation(word_tokenize(text)),\n",
    "preprocessor=lambda text: text.replace(\"<br />\", \" \"),)),\n",
    "('classifier', MLPClassifier(verbose = True))\n",
    "])\n",
    "bigram_clf.fit(X_train, y_train)\n",
    "bigram_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\"low price\",\"expensive\",\"cheap\",\"high quality\",\"low quality\",\"well made\",'poorly made','good product']\n",
    "y = [1,-1,-1,1,-1,1,-1,1]\n",
    "\n",
    "print(bigram_clf.score(X,y))\n",
    "print(bigram_clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isInDescription(text,description,title):\n",
    "    res = [] \n",
    "    for t in text:\n",
    "        ((a,b),num) = t\n",
    "        if (a + ' ' + b).lower() not in str(description).lower() and (a + ' ' + b).lower() not in str(title).lower():\n",
    "            res.append(t)\n",
    "    if len(res) > 0:\n",
    "        return res\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def getScore(text):\n",
    "    if len(text) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    res = 0\n",
    "    for t in text:\n",
    "        ((a,b),num) = t\n",
    "        res += bigram_clf.predict([(a + ' ' + b).lower()])* int(num)\n",
    "    return res\n",
    "\n",
    "def getText(text):\n",
    "    res = ''\n",
    "    for t in text:\n",
    "        ((a,b),num) = t\n",
    "        res += (a + ' ' + b).lower()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = df_product.merge(df_meta, left_on='asin', right_on='asin', how='inner')\n",
    "\n",
    "df_final['reviewText'] = df_final.apply(lambda x : isInDescription(x['reviewText'],x['description'],x['title']), axis=1)\n",
    "df_final = df_final[pd.notnull(df_final['reviewText'])]\n",
    "\n",
    "df_final[\"word\"] = df_final.apply(lambda x : getText(x['reviewText']), axis=1)\n",
    "\n",
    "df_final['score'] = 0\n",
    "df_final['score'] =  df_final.apply(lambda x : getScore(x[\"reviewText\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = {'score':['sum'],'word': lambda x: ' / '.join(set(x))}\n",
    "df_brand = df_final[['brand','word','score']].groupby(['brand']).agg(f)\n",
    "df_brand.columns = df_brand.columns.droplevel()\n",
    "df_brand = df_brand.reset_index()\n",
    "df_brand = df_brand.rename(columns={'sum': 'score', '<lambda>': 'word'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_brand.sort_values('score',ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
