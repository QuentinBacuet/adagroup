{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gzip\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import random \n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will explore opinion mining and sentiment analysis through the use of natural language processing. Our dataset consists of reviews of electronic products scraped form Amazon and available here: http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "The objective of this analysis is to use the reviews of a product to extract meaningful concepts about it. Such concepts can then be used to help the user make faster and more informed decisions when shopping. The extracted concepts consist of pairs of words that describe a property of the product. Those pairs are either of the type adjective-noun or adverb-past participle.\n",
    "\n",
    "For example:\n",
    "\n",
    "* Adjective - Nouns: (good, quality) (low, price) (best, deal)\n",
    "* Adverb - Past Participle pairs such as (well, made) (poorly, assembled)\n",
    "\n",
    "The concepts can then be categorised into positive and negative opinions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<ol>\n",
    "<li> <a href=\"#Data-Overview\">Data Overview</a>\n",
    "    <ol>\n",
    "        <li><a href=\"#Reading-the-data\">Reading the data</a></li>\n",
    "        <li><a href=\"#Data-Overview\">Formats</a></li>\n",
    "        <li><a href=\"#Missing-values\">Missing values</a></li>\n",
    "        <li><a href=\"#Distributions\">Distributions</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "<p></p>\n",
    "<li> <a href=\"#Characteristic-Exctraction\">Characteristic exctraction</a>\n",
    "<ol>\n",
    "        <li><a href=\"#Data-Overview\">Data Overview</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "<p></p>\n",
    "<li><a href=\"#Sentiment-Analysis\">Sentiment Analysis</a>\n",
    "<ol>\n",
    "        <li><a href=\"#SentiWordNet\">SentiWordNet</a></li>\n",
    "        <li><a href=\"#Machine-Learning\">Machine Learning</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "<p></p>\n",
    "<li><a href=\"#Applications\">Applications</a>\n",
    "<ol>\n",
    "        <li><a href=\"#Brand-Rating\">Brand Rating</a></li>\n",
    "    </ol>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data \n",
    "**<a href=\"#Table-of-Contents\">Table of contents</a>**\n",
    "\n",
    "For this intermediate milestone we will be using the following datasets:\n",
    "\n",
    "1. Sample of electronic review (1,689,188 reviews)\n",
    "2. Full dataset metadata\n",
    "\n",
    "#### 1. Electronic reviews sample\n",
    "Those easily fit in memory. Therefore, we can read the data line by line and store the result in a dataframe.\n",
    "#### 2. Full dataset metadata\n",
    "The metadata was downloaded from the cluster. It is not possible to load it in memory as when uncompressed it is more than 10GB in size. Since we care about electronic products for the moment, we read it line by line and only store the entries whose category is related to electronics. This results in a much smaller file of approx 500Mo (uncompressed) which can hold in memory.\n",
    "\n",
    "## Scalability\n",
    "We argue that processing the data locally will scale reasonably well to the rest of the Electronic reviews as our pipeline is applied separately for each product. That is, we only need to hold the reviews of one product as well as its metadata in memory at any given time.\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data file\n",
    "To open the data file we reuse the python code given by the author of the dataset. (See http://jmcauley.ucsd.edu/data/amazon/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "        \n",
    "def parseUncompressed(path):\n",
    "    g = open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    \"\"\"\n",
    "    Reads a data file and use it the build a DataFrame\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metadata_for_category(path, category):\n",
    "    \"\"\"\n",
    "    Reads the metadata file and extract only metadata for the given category\n",
    "    path: The path to the metadata file\n",
    "    category: The product category for which to extract the metadata\n",
    "    \n",
    "    Returns a DataFrame holding the metadata\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parseUncompressed(path):\n",
    "        if 'categories' in d:\n",
    "            for categories_list in d['categories']:\n",
    "                if categories_list[0] == category:\n",
    "                    df[i] = d\n",
    "                    i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and storing intermediate results\n",
    "DataFrames' `to_pickle` and `read_pickle` are used to respectively save and load serialized version of our intermediate results. We use it for example to store only the Electronics metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metadata_for_category('data/metadata.json', 'Electronics')\n",
    "df.to_pickle('data/metadata_electronics_serialized.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = getDF('data/reviews_Electronics_5.json.gz')\n",
    "df.to_pickle('data/electronics_serialized.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elec = pd.read_pickle('electronics_serialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta = pd.read_pickle('metadata_electronics_serialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elec['reviewTime']  = pd.to_datetime(df_elec['reviewTime'],format='%m %d, %Y')\n",
    "df_elec.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = df_meta[pd.notnull(df_meta['brand'])]\n",
    "df_meta.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged = df_meta.merge(df_elec, left_on='asin', right_on='asin', how='inner')\n",
    "df_merged['reviewLength'] = df_merged['reviewText'].str.len()\n",
    "\n",
    "df_plot = df_merged.copy()\n",
    "df_plot = df_plot[pd.notnull(df_plot['price'])]\n",
    "df_plot = df_plot[pd.notnull(df_plot['reviewLength'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df_plot[['price','reviewLength','overall']].sample(100000,random_state = 0), alpha=0.2, figsize=(15, 15), diagonal='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(y='reviewLength', x='price', data=df_plot,scatter_kws={'s':5},line_kws={'color':'r'},order=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='overall', x='reviewLength', data=df_plot, orient='h', showfliers=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "sns.boxplot(data= df_plot[['price']],orient='h', showfliers=False,ax=axes[0,0])\n",
    "df_plot[['price']].plot.kde(ax=axes[0,1])\n",
    "sns.boxplot(data= df_plot[['reviewLength']],orient='h', showfliers=False,ax=axes[1,0])\n",
    "df_plot[['reviewLength']].plot.kde(ax=axes[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "d = df_plot[['price']]\n",
    "ax = d.plot.kde()\n",
    "x = ax.get_children()[0]._x\n",
    "y = ax.get_children()[0]._y\n",
    "\n",
    "print(d.mean())\n",
    "\n",
    "scale = 70\n",
    "loc = -500\n",
    "\n",
    "pdf_fitted = scipy.stats.expon.pdf(x - loc, scale=scale)\n",
    "plt.plot(pdf_fitted,label= ('exp lambda = ' + str(scale)))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "d = df_plot[['reviewLength']].sample(100000)\n",
    "ax = d.plot.kde()\n",
    "\n",
    "x = ax.get_children()[0]._x\n",
    "y = ax.get_children()[0]._y\n",
    "\n",
    "scale = 1000\n",
    "loc = -500\n",
    "\n",
    "pdf_fitted = scipy.stats.pareto.pdf(x,loc=loc,b = 2, scale=scale)\n",
    "plt.plot(pdf_fitted,label= 'exp')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[['price','reviewLength','overall']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characteristic Exctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterTags(w1,w2):\n",
    "    return (nltk.pos_tag(nltk.word_tokenize(w1))[0][1] == 'JJ' and nltk.pos_tag(nltk.word_tokenize(w2))[0][1] == 'NN') or \\\n",
    "     (nltk.pos_tag(nltk.word_tokenize(w1))[0][1] == 'RB' and nltk.pos_tag(nltk.word_tokenize(w2))[0][1] == 'VBN')\n",
    "\n",
    "def getBest(text):\n",
    "    ignored_words = nltk.corpus.stopwords.words('english')\n",
    "    word_filter = lambda w: len(w) < 3 or w.lower() in ignored_words\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    \n",
    "    finder = nltk.BigramCollocationFinder.from_words(tokens)\n",
    "    finder.apply_word_filter(word_filter)    \n",
    "    finder.apply_freq_filter(1)\n",
    "    res = finder.ngram_fd.most_common(1)\n",
    "        \n",
    "    res = [x for x in res if filterTags(x[0][0],x[0][1])]\n",
    "\n",
    "    if(len(res) > 0):\n",
    "        return res\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "df_product = df_elec.groupby([\"asin\"])['reviewText'].agg(lambda x:''.join(set(x))).reset_index()\n",
    "df_product = df_product.sample(n=10000)\n",
    "\n",
    "start = timer()\n",
    "df_product[\"reviewText\"] = df_product[\"reviewText\"].apply(lambda x: getBest(x))\n",
    "end = timer()\n",
    "print(end - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = df_product.dropna(how = 'any')\n",
    "df_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "We now want to be able to categorise the opinions we extracted in the previous part of this notebook. One way of doing this is to use [SentiWordNet](http://nmis.isti.cnr.it/sebastiani/Publications/LREC06.pdf). SentiWordNet is a lexical resource for performing sentiment analysis on texts. It is base on WordNet. Fortunately, the NLTK package for python provides an interface for using SentiWordNet.\n",
    "\n",
    "We implemented a class on top of NLTK's support for SentiWordNet in order to provide a convenient interface to tokenize and classify opinions. The implementation is encapsulated in the SentimentAnalyzer class in the [SentimentAnalyser.py](SentimentAnalyser.py) file.\n",
    "\n",
    "### Classifying opinions\n",
    "\n",
    "SentiWordNet provides a positivity score for each word which can then be used to asses the positivity of a sentence of for our pipeline, a pair of words. A score above than 0 denotes a positive connotation of the word while a score below 0 denotes a negative connotation. See the following examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SentimentAnalyser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyzer = SentimentAnalyser()\n",
    "\n",
    "examples = ['Hello world', 'The screen is poorly assembled', 'Worst purchase I\\'ve done', 'Excellent quality', 'Best deal']\n",
    "\n",
    "for sentence in examples:\n",
    "    print(\"{} : {}\".format(sentence, sentimentAnalyzer.sentiment_score_for_raw_sentence(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using those score, we would then classify the second and the third as being negative ans the fourth and fifth as being positive. While looking very promising this approach has a major flaw for our application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['Cheap quality', 'Low price']\n",
    "\n",
    "for sentence in examples:\n",
    "    print(\"{} : {}\".format(sentence, sentimentAnalyzer.sentiment_score_for_raw_sentence(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not able to classify correctly opinions which are positive but writte with negatively connoted words and vice versa. This is why we propose an alternative approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis, revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "df_ML = df_elec[(df_elec[\"reviewText\"].str.len()<100)].copy()\n",
    "df_ML['score'] = df_elec[\"overall\"].apply(lambda x : -1 if x < 3 else 1)\n",
    "df_ML[\"reviewText\"] = df_ML[\"reviewText\"].apply(lambda x: x.lower())\n",
    "\n",
    "df_0 = (df_ML[df_ML[\"score\"] == -1])\n",
    "df_1 = (df_ML[df_ML[\"score\"] == 1])\n",
    "\n",
    "if df_0.shape[0] > df_1.shape[0]:\n",
    "    df_0 = df_0.sample(df_1.shape[0])\n",
    "else:\n",
    "    df_1 = df_1.sample(df_0.shape[0])\n",
    "    \n",
    "sentiment_data = pd.concat([df_0, df_1])\n",
    "X = sentiment_data[\"reviewText\"]\n",
    "y = sentiment_data[\"score\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_clf = Pipeline([\n",
    "('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "ngram_range=(1, 2),\n",
    "tokenizer=word_tokenize, \n",
    "# tokenizer=lambda text: mark_negation(word_tokenize(text)),\n",
    "preprocessor=lambda text: text.replace(\"<br />\", \" \"),)),\n",
    "('classifier', MLPClassifier(verbose = True))\n",
    "])\n",
    "bigram_clf.fit(X_train, y_train)\n",
    "bigram_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\"low price\",\"expensive\",\"cheap\",\"high quality\",\"low quality\",\"well made\",'poorly made','good product']\n",
    "y = [1,-1,-1,1,-1,1,-1,1]\n",
    "\n",
    "print(bigram_clf.score(X,y))\n",
    "print(bigram_clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isInDescription(text,description,title):\n",
    "    res = [] \n",
    "    for t in text:\n",
    "        ((a,b),num) = t\n",
    "        if (a + ' ' + b).lower() not in str(description).lower() and (a + ' ' + b).lower() not in str(title).lower():\n",
    "            res.append(t)\n",
    "    if len(res) > 0:\n",
    "        return res\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def getScore(text):\n",
    "    if len(text) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    res = 0\n",
    "    for t in text:\n",
    "        ((a,b),num) = t\n",
    "        res += bigram_clf.predict([(a + ' ' + b).lower()])* int(num)\n",
    "    return res\n",
    "\n",
    "def getText(text):\n",
    "    res = ''\n",
    "    for t in text:\n",
    "        ((a,b),num) = t\n",
    "        res += (a + ' ' + b).lower()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = df_product.merge(df_meta, left_on='asin', right_on='asin', how='inner')\n",
    "\n",
    "df_final['reviewText'] = df_final.apply(lambda x : isInDescription(x['reviewText'],x['description'],x['title']), axis=1)\n",
    "df_final = df_final[pd.notnull(df_final['reviewText'])]\n",
    "\n",
    "df_final[\"word\"] = df_final.apply(lambda x : getText(x['reviewText']), axis=1)\n",
    "\n",
    "df_final['score'] = 0\n",
    "df_final['score'] =  df_final.apply(lambda x : getScore(x[\"reviewText\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = {'score':['sum'],'word': lambda x: ' / '.join(set(x))}\n",
    "df_brand = df_final[['brand','word','score']].groupby(['brand']).agg(f)\n",
    "df_brand.columns = df_brand.columns.droplevel()\n",
    "df_brand = df_brand.reset_index()\n",
    "df_brand = df_brand.rename(columns={'sum': 'score', '<lambda>': 'word'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_brand.sort_values('score',ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
